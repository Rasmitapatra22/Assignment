{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        " 1. What is TensorFlow 2.0, and how is it different from TensorFlow 1.x\n",
        "\n",
        " TensorFlow 2. x introduces a more simplified and consistent API compared to TensorFlow 1. x. Many redundant or outdated APIs have been removed or consolidated in TensorFlow 2.\n",
        "\n",
        "\n",
        " 2. How do you install TensorFlow 2.0\n",
        "\n",
        "To install TensorFlow 2.0, you can use pip, which is the package installer for Python. You can install the CPU version or the GPU version depending on your hardware. For CPU, use pip install tensorflow. For GPU, use pip install tensorflow-gpu.\n",
        "\n",
        "\n",
        "\n",
        "3.  What is the primary function of the tf.function in TensorFlow 2.0\n",
        "\n",
        "\n",
        "The primary function of tf.function in TensorFlow 2.0 is to convert a Python function, especially one that uses Python control flow, into a TensorFlow graph for optimized execution. This graph can then be executed more efficiently using TensorFlow's optimized runtime. Essentially, tf.function enables graph execution, which offers benefits like improved performance and portability.\n",
        "\n",
        " 4. What is the purpose of the Model class in TensorFlow 2.0\n",
        "\n",
        " In TensorFlow 2.0, the Model class is a fundamental building block for creating and managing machine learning models, particularly within the Keras API. It provides a high-level, user-friendly way to define, train, evaluate, and predict using neural networks.\n",
        "\n",
        "\n",
        " 5. How do you create a neural network using TensorFlow 2.0\n",
        "\n",
        " To create a neural network using TensorFlow 2.0, you typically follow these steps: define the model architecture using the tf.keras library, compile the model with an optimizer, loss function, and metrics, and then train the model on your data using the model.fit() method.\n",
        "\n",
        " 5. What is the importance of Tensor Space in TensorFlow\n",
        "\n",
        " TensorFlow supports data in the shape of tensors, which are multidimensional arrays of greater dimensions. Arrays with several dimensions are highly useful for managing enormous volumes of data.\n",
        "\n",
        " 6. How can TensorBoard be integrated with TensorFlow 2.0\n",
        "\n",
        " Start by installing TF 2.0 and loading the TensorBoard notebook extension: For Jupyter users: If you've installed Jupyter and TensorBoard into the same virtualenv, then you should be good to go.\n",
        "\n",
        " 7.What is the purpose of TensorFlow Playground\n",
        "\n",
        " TensorFlow Playground is an educational tool and interactive visualization for learning about neural networks. It allows users to experiment with different neural network parameters and see the effects in real-time, helping them understand how these parameters influence the learning process. Essentially, it's a browser-based playground for exploring and visualizing neural network concepts.\n",
        "\n",
        " 8. What is Netron, and how is it useful for deep learning models\n",
        "\n",
        " NEUTRON\" is an algorithm that combines machine learning with optimization techniques for inverse design problems, specifically in material selection and structural parameter optimization. It's a type of deep learning model, where the \"Neutron\" component refers to the neural network-based optimization approach, not the neutron particle from physics. Deep learning models are used to analyze and process neutron scattering data, as well as to improve neutron detection and image reconstruction.\n",
        "\n",
        " 9. What is the difference between TensorFlow and PyTorch\n",
        "\n",
        "\n",
        " PyTorch and TensorFlow are both popular deep learning frameworks, but they differ in their approach to computation and ease of use. PyTorch excels in dynamic computation and Python integration, making it favored for research and prototyping, while TensorFlow is renowned for its static computation graphs and scalability, ideal for production and large-scale deployment.\n",
        "\n",
        " 11. How do you install PyTorch\n",
        "\n",
        " Request Resources: Request a compute node, specifying GPU requirements. ...\n",
        "Set Environment Variables: Set the Python and CUDA Toolkit versions. ...\n",
        "Create Conda Environment: Create a new conda environmnet with the necessary CUDA tools. ...\n",
        "Activate Environment: ...\n",
        "Install TensorFlow and PytOrch:\n",
        "\n",
        " 12. What is the basic structure of a PyTorch neural network\n",
        " A PyTorch neural network is built from interconnected layers and modules that perform operations on data. The torch.nn namespace provides the building blocks for these networks. PyTorch neural networks are implemented as subclasses of torch.nn.Module, allowing for easy construction and management of complex architectures.\n",
        "\n",
        "\n",
        " 13. What is the significance of tensors in PyTorch\n",
        "\n",
        " Tensors are the fundamental data structure in PyTorch, serving as the basis for representing and manipulating numerical data, including images, audio, and other forms of data used in machine learning models. They are essentially multi-dimensional arrays, similar to NumPy's ndarrays, but with the added benefit of being able to run on GPUs for accelerated computation. Tensors are essential for building and training neural networks because they allow for efficient manipulation of data during the forward and backward passes of the model.\n",
        "\n",
        " 14. What is the difference between torch.Tensor and torch.cuda.Tensor in PyTorch\n",
        "\n",
        " torch. tensor infers the dtype automatically, while torch. Tensor returns a torch. FloatTensor\n",
        "\n",
        "\n",
        " 15. What is the purpose of the torch.optim module in PyTorch\n",
        "\n",
        " The torch.optim module in PyTorch provides various optimization algorithms to update the parameters of a neural network during training. It offers common optimizers like SGD, Adam, and RMSprop, and facilitates efficient weight updates, including features like learning rate scheduling and weight decay.\n",
        "\n",
        "\n",
        " 16. What are some common activation functions used in neural networks\n",
        "\n",
        " Some of the most common activation functions used in neural networks include ReLU (Rectified Linear Unit), Sigmoid, and Tanh (Hyperbolic Tangent). These functions introduce non-linearity into the network, allowing it to learn complex relationships in data.\n",
        "\n",
        " What is the difference between torch.nn.Module and torch.nn.Sequential in PyTorch\n",
        "\n",
        " torch.nn Module\ttorch.nn.functional Module\n",
        "It follows the Object-oriented approach with pre-defined layers as the Classes.\tIt is based on the Functional approach with stateless operations without any learnable operators.\n",
        "\n",
        "\n",
        " How can you monitor training progress in TensorFlow 2.0\n",
        "\n",
        " Step 1: Loading and Preprocessing Data.\n",
        "Step 2: Model Building.\n",
        "Step 3: Compiling the Model.\n",
        "Step 4: Setting Up TensorBoard.\n",
        "Visualizing the training progress in TensorBoard.\n",
        "27 Mar 2024\n",
        "\n",
        "\n",
        " 19. How does the Keras API fit into TensorFlow 2.0\n",
        "\n",
        "\n",
        " Keras and TensorFlow 2.0 provide you with three methods to implement your own neural network architectures:\n",
        "\n",
        "Sequential API\n",
        "Functional API\n",
        "Model subclassing\n",
        "\n",
        "\n",
        " 20. What is an example of a deep learning project that can be implemented using TensorFlow 2.0\n",
        "\n",
        "\n",
        " A practical deep learning project using TensorFlow 2.0 could involve building a model to detect objects in images or videos. This can be done by using a pre-trained model, like TensorFlow's Object Detection API, and fine-tuning it on a custom dataset of images or videos with labeled objects. This project would involve data loading, model training, and finally, model evaluation and deployment.\n",
        "\n",
        "\n",
        " 21. What is the main advantage of using pre-trained models in TensorFlow and PyTorch?\n",
        "\n",
        "\n",
        " The primary advantage of using pre-trained models in TensorFlow and PyTorch is accelerating the development and training process of deep learning models. This is achieved by leveraging knowledge learned on vast datasets, allowing for faster fine-tuning on new, smaller datasets."
      ],
      "metadata": {
        "id": "LRBAGbndWj9i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "       **Practical**\n",
        "\n",
        "\n",
        " How do you install and verify that TensorFlow 2.0 was installed successfully\n",
        "\n",
        " How can you define a simple function in TensorFlow 2.0 to perform addition\n",
        " How can you create a simple neural network in TensorFlow 2.0 with one hidden layer\n",
        " How can you visualize the training progress using TensorFlow and Matplotlib\n",
        " How do you install PyTorch and verify the PyTorch installation\n",
        " How do you create a simple neural network in PyTorch\n",
        " How do you define a loss function and optimizer in PyTorch\n",
        " How do you implement a custom loss function in PyTorch\n",
        " How do you save and load a TensorFlow model?\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zk5kMW5FbvZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1.How do you install and verify that TensorFlow 2.0 was installed successfully\n",
        "\n",
        "\n",
        "$ python 3 -V\n",
        "$ sudo apt install -y python3-pip\n",
        "$ pip install package_name\n",
        "$ sudo apt install -y python3-venv\n",
        "$ mkdir environments\n",
        "$ cd environments\n",
        "\n",
        "$ python3 -m venv my_env\n",
        "$ ls my_env\n",
        "$ source my_env/bin/activate\n"
      ],
      "metadata": {
        "id": "Q0qqj7y4bsYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "a=tf.constant(7)\n",
        "b=tf.constant(10)\n",
        "c = tf.add(a,b)\n",
        "simple_session = tf.Session()\n",
        "value_of_c = simple_session.run(c)\n",
        "print(value_of_c)   # 17\n",
        "simple_session.close()\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "#a placeholder is like a variable that you can\n",
        "#set later\n",
        "a = tf.placeholder(tf.float32)\n",
        "b = tf.placeholder(tf.float32)\n",
        "#build the sum operation\n",
        "c = a+b\n",
        "#get the tensorflow session\n",
        "sess = tf.Session()\n",
        "\n",
        "#initialize all variables\n",
        "sess.run(tf.initialize_all_variables())\n",
        "\n",
        "#Now you want to sum 2 numbers\n",
        "#first set up a dictionary\n",
        "#that includes the numbers\n",
        "#The key of the dictionary\n",
        "#matches the placeholders\n",
        "# required for the sum operation\n",
        "feed_dict = {a:2.0, b:3.0}\n",
        "\n",
        "#now run the sum operation\n",
        "ppx = sess.run([c], feed_dict)\n",
        "\n",
        "#print the result\n",
        "print(ppx)"
      ],
      "metadata": {
        "id": "uS9J2JAgc2KI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# be sure to change the file path\n",
        "# if you have the dataset in another\n",
        "# directly than the working folder\n",
        "df = pd.read_csv('winequality-red.csv')\n",
        "\n",
        "df.head()\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# 75% of the data is selected\n",
        "train_df = df.sample(frac=0.75, random_state=4)\n",
        "\n",
        "# it drops the training data\n",
        "# from the original dataframe\n",
        "val_df = df.drop(train_df.index)\n"
      ],
      "metadata": {
        "id": "45GRMDhAdI3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "print(len(x_train))\n",
        "print(len(x_test))\n",
        "print(x_train.shape)\n",
        "\n",
        "log_dir = '/content/drive/My Drive/logs/'\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(100, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "model.fit(x_train, y_train, epochs=5, callbacks=[tb_callback])\n"
      ],
      "metadata": {
        "id": "IA70Z3YrdU8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "batch_size = 64\n",
        "num_epochs = 10\n",
        "learning_rate = 0.01\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))  # Mean and Std of MNIST dataset\n",
        "])\n",
        "train_dataset = datasets.MNIST(root='.', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='.', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 512)\n",
        "        self.fc2 = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)  # Flatten the image\n",
        "        x = F.relu(self.fc1(x))  # ReLU activation\n",
        "        x = self.fc2(x)  # Output layer\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "7rOV_fu4dfSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.datasets import FakeData\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "class MLP(nn.Module):\n",
        "  '''\n",
        "    Multilayer Perceptron.\n",
        "  '''\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "      nn.Flatten(),\n",
        "      nn.Linear(28 * 28 * 3, 64),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(64, 32),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(32, 1),\n",
        "      nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    '''Forward pass'''\n",
        "    return self.layers(x)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "  # Set fixed random number seed\n",
        "  torch.manual_seed(42)\n",
        "\n",
        "  # Prepare FakeData dataset\n",
        "  dataset = FakeData(size=15000, image_size=(3, 28, 28), num_classes=2, transform=transforms.ToTensor())\n",
        "  trainloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True, num_workers = 4, pin_memory = True)\n",
        "\n",
        "  # Initialize the MLP\n",
        "  mlp = MLP()\n",
        "\n",
        "  # Define the loss function and optimizer\n",
        "  loss_function = nn.BCELoss()\n",
        "  optimizer = torch.optim.Adam(mlp.parameters(), lr=1e-4)\n",
        "\n",
        "  # Run the training loop\n",
        "  for epoch in range(0, 5): # 5 epochs at maximum\n",
        "\n",
        "    # Print epoch\n",
        "    print(f'Starting epoch {epoch+1}')\n",
        "\n",
        "    # Set current loss value\n",
        "    current_loss = 0.0\n",
        "\n",
        "    # Iterate over the DataLoader for training data\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "\n",
        "      # Get inputs\n",
        "      inputs, targets = data\n",
        "\n",
        "      # Prepare targets\n",
        "      targets = targets \\\n",
        "                  .type(torch.FloatTensor) \\\n",
        "                  .reshape((targets.shape[0], 1))\n",
        "\n",
        "      # Zero the gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Perform forward pass\n",
        "      outputs = mlp(inputs)\n",
        "\n",
        "      # Compute loss\n",
        "      loss = loss_function(outputs, targets)\n",
        "\n",
        "      # Perform backward pass\n",
        "      loss.backward()\n",
        "\n",
        "      # Perform optimization\n",
        "      optimizer.step()\n",
        "\n",
        "      # Print statistics\n",
        "      current_loss += loss.item()\n",
        "      if i % 10 == 0:\n",
        "          print('Loss after mini-batch %5d: %.3f' %\n",
        "                (i + 1, current_loss / 500))\n",
        "          current_loss = 0.0\n",
        "\n",
        "  # Process is complete.\n",
        "  print('Training process has finished.')"
      ],
      "metadata": {
        "id": "qKkYpm1Bd25P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class CustomLoss(nn.Module):\n",
        "    def __init__(self, weight):\n",
        "        super(CustomLoss, self).__init__()\n",
        "        self.weight = weight\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        # Compute the loss\n",
        "        loss = torch.mean(self.weight * (input - target) ** 2)\n",
        "        return loss\n",
        "\n",
        "# Example usage:\n",
        "# Create an instance of the custom loss function\n",
        "weight = torch.tensor(0.5)  # You can adjust the weight according to your needs\n",
        "loss_function = CustomLoss(weight)\n",
        "\n",
        "# Define input and target tensors\n",
        "input_tensor = torch.randn(3, requires_grad=True)\n",
        "target_tensor = torch.randn(3)\n",
        "\n",
        "# Compute the loss\n",
        "loss = loss_function(input_tensor, target_tensor)\n",
        "print(loss)\n"
      ],
      "metadata": {
        "id": "LTBqH0coevJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout, MaxPooling2D, BatchNormalization\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "\n",
        "cifar10 = tf.keras.datasets.cifar10\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "y_train, y_test = y_train.flatten(), y_test.flatten()\n",
        "K = len(set(y_train))\n",
        "i = Input(shape=x_train[0].shape)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(i)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "x = Dense(K, activation='softmax')(x)\n",
        "\n",
        "model = Model(i, x)\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "ziXVuGZmfMmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "def get_model():\n",
        "    # Create a simple model.\n",
        "    inputs = keras.Input(shape=(32,))\n",
        "    outputs = keras.layers.Dense(1)(inputs)\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    model.compile(optimizer=keras.optimizers.Adam(), loss=\"mean_squared_error\")\n",
        "    return model\n",
        "\n",
        "\n",
        "model = get_model()\n",
        "\n",
        "# Train the model.\n",
        "test_input = np.random.random((128, 32))\n",
        "test_target = np.random.random((128, 1))\n",
        "model.fit(test_input, test_target)\n",
        "\n",
        "# Calling `save('my_model.keras')` creates a zip archive `my_model.keras`.\n",
        "model.save(\"my_model.keras\")\n",
        "\n",
        "# It can be used to reconstruct the model identically.\n",
        "reconstructed_model = keras.models.load_model(\"my_model.keras\")\n",
        "\n",
        "# Let's check:\n",
        "np.testing.assert_allclose(\n",
        "    model.predict(test_input), reconstructed_model.predict(test_input)\n",
        ")\n",
        "class CustomLayer(keras.layers.Layer):\n",
        "    def __init__(self, sublayer, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.sublayer = sublayer\n",
        "\n",
        "    def call(self, x):\n",
        "        return self.sublayer(x)\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "        config = {\n",
        "            \"sublayer\": keras.saving.serialize_keras_object(self.sublayer),\n",
        "        }\n",
        "        return {**base_config, **config}\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        sublayer_config = config.pop(\"sublayer\")\n",
        "        sublayer = keras.saving.deserialize_keras_object(sublayer_config)\n",
        "        return cls(sublayer, **config)\n",
        "\n",
        "\n",
        "        # Clear all previously registered custom objects\n",
        "keras.saving.get_custom_objects().clear()\n",
        "\n",
        "\n",
        "# Upon registration, you can optionally specify a package or a name.\n",
        "# If left blank, the package defaults to `Custom` and the name defaults to\n",
        "# the class name.\n",
        "@keras.saving.register_keras_serializable(package=\"MyLayers\")\n",
        "class CustomLayer(keras.layers.Layer):\n",
        "    def __init__(self, factor):\n",
        "        super().__init__()\n",
        "        self.factor = factor\n",
        "\n",
        "    def call(self, x):\n",
        "        return x * self.factor\n",
        "\n",
        "    def get_config(self):\n",
        "        return {\"factor\": self.factor}\n",
        "\n",
        "\n",
        "@keras.saving.register_keras_serializable(package=\"my_package\", name=\"custom_fn\")\n",
        "def custom_fn(x):\n",
        "    return x**2\n",
        "\n",
        "\n",
        "# Create the model.\n",
        "def get_model():\n",
        "    inputs = keras.Input(shape=(4,))\n",
        "    mid = CustomLayer(0.5)(inputs)\n",
        "    outputs = keras.layers.Dense(1, activation=custom_fn)(mid)\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    model.compile(optimizer=\"rmsprop\", loss=\"mean_squared_error\")\n",
        "    return model\n",
        "\n",
        "\n",
        "# Train the model.\n",
        "def train_model(model):\n",
        "    input = np.random.random((4, 4))\n",
        "    target = np.random.random((4, 1))\n",
        "    model.fit(input, target)\n",
        "    return model\n",
        "\n",
        "\n",
        "test_input = np.random.random((4, 4))\n",
        "test_target = np.random.random((4, 1))\n",
        "\n",
        "model = get_model()\n",
        "model = train_model(model)\n",
        "model.save(\"custom_model.keras\")\n",
        "\n",
        "# Now, we can simply load without worrying about our custom objects.\n",
        "reconstructed_model = keras.models.load_model(\"custom_model.keras\")\n",
        "\n",
        "# Let's check:\n",
        "np.testing.assert_allclose(\n",
        "    model.predict(test_input), reconstructed_model.predict(test_input)\n",
        ")"
      ],
      "metadata": {
        "id": "rN68orKAf4FC"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}